@online{24TopAI,
  title = {24 {{Top AI Statistics}} \& {{Trends In}} 2023 – {{Forbes Advisor}}},
  url = {https://www.forbes.com/advisor/business/ai-statistics/},
  urldate = {2023-10-07},
  file = {/home/jon/Zotero/storage/AAQDVT3K/ai-statistics.html}
}

@online{AirflowVsLuigi,
  title = {Airflow vs {{Luigi}} vs {{Argo}} vs {{Kubeflow}} vs {{MLFlow}}},
  url = {https://www.datarevenue.com/en-blog/airflow-vs-luigi-vs-argo-vs-mlflow-vs-kubeflow},
  urldate = {2023-10-04},
  abstract = {Luigi is simple, Airflow is powerful, and Argo is Kubernetes-based. This post offers a detailed description and comparison of workflow orchestration tools.},
  langid = {english},
  file = {/home/jon/Zotero/storage/XSJ3JUAS/airflow-vs-luigi-vs-argo-vs-mlflow-vs-kubeflow.html}
}

@misc{amazonwebservicesincHighPerformanceComputing,
  title = {High {{Performance Computing Lens}} - {{AWS Well-Architected Framework}}},
  author = {Amazon Web Services, Inc},
  langid = {english},
  file = {/home/jon/Zotero/storage/DD2HD5LB/High Performance Computing Lens - AWS Well-Archite.pdf}
}

@software{Ansible2023,
  title = {Ansible},
  date = {2023-10-22T14:02:20Z},
  origdate = {2012-03-06T14:58:02Z},
  url = {https://github.com/ansible/ansible},
  urldate = {2023-10-22},
  abstract = {Ansible is a radically simple IT automation platform that makes your applications and systems easier to deploy and maintain. Automate everything from code deployment to network configuration to cloud management, in a language that approaches plain English, using SSH, with no agents to install on remote systems. https://docs.ansible.com.},
  organization = {{Ansible}},
  keywords = {ansible,hacktoberfest,python}
}

@software{ArgoprojArgoworkflows2023,
  title = {Argoproj/Argo-Workflows},
  date = {2023-10-07T11:56:29Z},
  origdate = {2017-08-21T18:50:44Z},
  url = {https://github.com/argoproj/argo-workflows},
  urldate = {2023-10-07},
  abstract = {Workflow Engine for Kubernetes},
  organization = {{Argo Project}},
  keywords = {airflow,argo,argo-workflows,batch-processing,cloud-native,cncf,dag,data-engineering,gitops,hacktoberfest,k8s,knative,kubernetes,machine-learning,mlops,pipelines,workflow,workflow-engine}
}

@online{ArkoudacontribArkoudadockerMain,
  title = {Arkouda-Contrib/Arkouda-Docker at Main · {{Bears-R-Us}}/Arkouda-Contrib},
  url = {https://github.com/Bears-R-Us/arkouda-contrib/tree/main/arkouda-docker},
  urldate = {2023-10-23},
  abstract = {a place for contributed functionality for arkouda. Contribute to Bears-R-Us/arkouda-contrib development by creating an account on GitHub.},
  langid = {english},
  organization = {{GitHub}},
  file = {/home/jon/Zotero/storage/QMDNAI36/arkouda-docker.html}
}

@software{ArkoudaGituhbRepository2023,
  title = {Arkouda {{Gituhb}} Repository},
  date = {2023-10-20T16:08:34Z},
  origdate = {2019-03-22T15:51:38Z},
  url = {https://github.com/Bears-R-Us/arkouda},
  urldate = {2023-10-23},
  abstract = {Arkouda (αρκούδα): Interactive Data Analytics at Supercomputing Scale :bear:},
  organization = {{Bears-R-Us}},
  keywords = {chapel,data,data-analysis,data-science,distributed-computing,eda,hpc,python}
}

@online{ArtifacthubPachyderm,
  title = {Artifacthub Pachyderm 2.6.4},
  url = {https://artifacthub.io/packages/helm/pachyderm/pachyderm/2.6.4},
  urldate = {2023-10-18},
  abstract = {Explainable, repeatable, scalable data science},
  langid = {english},
  file = {/home/jon/Zotero/storage/39KTRTTN/2.6.html}
}

@book{barfodMulticriteriaDecisionAnalysis2014,
  title = {Multi-Criteria Decision Analysis for Use in Transport Decision Making},
  editorb = {Barfod, Michael Bruhn and Leleur, Steen},
  editorbtype = {redactor},
  date = {2014},
  publisher = {{DTU Transport}},
  location = {{DTU Lyngby}},
  abstract = {1 IntroductionThe most common methodology applied so far to the evaluation of transport systems has been conventional cost-benefit analysis (CBA) (Janic, 2003), which supported by traffic- and impact model calculations provides the decision-makers with a monetary assessment of the project’s feasibility. A socioeconomicanalysis is in this respect a further development of the traditional CBA capturing the economic value of social benefits by translating social objectives into financial measures of benefits (Wright et al.,2009). Internationally seen there has been a growing awareness over the recent years that besides thesocial costs and benefits associated with transport other impacts that are more difficult to monetise should also have influence on the decision making process. This is in many developed countries realised in the transport planning, which takes into account a wide range of impacts of also a strategic character (van Exelet al., 2002). Accordingly, appraisal methodologies are undergoing substantial changes in order to deal with the developments (Vickerman, 2000) that are varying from country to country and leading to different approaches (Banister and Berechman, 2000). It is, however, commonly agreed that the final decisionmaking concerning transport infrastructure projects in many cases will depend on other aspects besides the monetary ones assessed in a socio-economic analysis. Nevertheless, an assessment framework such as the Danish one (DMT, 2003) does not provide any specific guidelines on how to include the strategic impacts; it merely suggests describing the impacts verbally and keeping them in mind during the decision process.A coherent, well-structured, flexible, straight forward evaluation method, taking into account all the requirements of a transport infrastructure project is for this reason required. An appropriate ex-ante evaluation method for such projects can be based on multi-criteria decision analysis (MCDA) (Tsamboulas, 2007. Vreeker et al. 2002), which in most cases can be combined with a CBA (Leleur, 2000). Scanning the literature (Belton and Stewart, 2002; Goodwin and Wright, 2009; Keeney and Raiffa, 1993; von Winterfeldt and Edwards, 1986) it is found that the use of MCDA in the decision process usually provides some or all ofthe following features:1. Improvement of the satisfaction with the decision process2. Improvement of the quality of the decision itself3. Increased productivity of the decision-makersMCDA can in this respect be seen as a tool for appraisal of different alternatives, when several points of view and priorities are taken into account to produce a common output. Hence, it is very useful during the formulation of a decision support system (DSS) designed to deal with complex issues. The literature on DSS is extensive, providing a sound basis for the methodologies employed and the mathematics involved. Moreover, there are numerous systems covering several disciplines, policy contexts and users’ needs for specific application environments (Janic, 2003; Salling et al., 2007; Tsamboulas and Mikroudis, 2006). The use of DSS for solving MCDA problems has among others been treated by Barfod (2012), Chen et al. (2008) and Larichev et al. (2002), where it is shown that a DSS can effectively support a decision making process making use of appropriate MCDA methodologies.},
  file = {/home/jon/Zotero/storage/AUHJXNDK/DTU_Transport_Compendium_Part_2_MCDA_.pdf}
}

@inproceedings{beltreEnablingHPCWorkloads2019,
  title = {Enabling {{HPC Workloads}} on {{Cloud Infrastructure Using Kubernetes Container Orchestration Mechanisms}}},
  booktitle = {2019 {{IEEE}}/{{ACM International Workshop}} on {{Containers}} and {{New Orchestration Paradigms}} for {{Isolated Environments}} in {{HPC}} ({{CANOPIE-HPC}})},
  author = {Beltre, Angel M. and Saha, Pankaj and Govindaraju, Madhusudhan and Younge, Andrew and Grant, Ryan E.},
  date = {2019-11},
  pages = {11--20},
  doi = {10.1109/CANOPIE-HPC49598.2019.00007},
  abstract = {Containers offer a broad array of benefits, including a consistent lightweight runtime environment through OS-level virtualization, as well as low overhead to maintain and scale applications with high efficiency. Moreover, containers are known to package and deploy applications consistently across varying infrastructures. Container orchestrators manage a large number of containers for microservices based cloud applications. However, the use of such service orchestration frameworks towards HPC workloads remains relatively unexplored. In this paper we study the potential use of Kubernetes on HPC infrastructure for use by the scientific community. We directly compare both its features and performance against Docker Swarm and bare metal execution of HPC applications. Herein, we detail the configurations required for Kubernetes to operate with containerized MPI applications, specifically accounting for operations such as (1) underlying device access, (2) inter-container communication across different hosts, and (3) configuration limitations. This evaluation quantifies the performance difference between representative MPI workloads running both on bare metal and containerized orchestration frameworks with Kubernetes, operating over both Ethernet and InfiniBand interconnects. Our results show that Kubernetes and Docker Swarm can achieve near bare metal performance over RDMA communication when high performance transports are enabled. Our results also show that Kubernetes presents overheads for several HPC applications over TCP/IP protocol. However, Docker Swarm's throughput is near bare metal performance for the same applications.},
  eventtitle = {2019 {{IEEE}}/{{ACM International Workshop}} on {{Containers}} and {{New Orchestration Paradigms}} for {{Isolated Environments}} in {{HPC}} ({{CANOPIE-HPC}})},
  keywords = {Cloud computing,Cloud Computing,Container,Containers,HPC,Kubernetes,Metals,Overlay networks,Performance,Protocols,Runtime,Software},
  file = {/home/jon/Zotero/storage/H4CQDCX7/Beltre et al. - 2019 - Enabling HPC Workloads on Cloud Infrastructure Usi.pdf;/home/jon/Zotero/storage/7VFPBGTM/stamp.html}
}

@article{boehmSpiralModelSoftware1988,
  title = {A Spiral Model of Software Development and Enhancement},
  author = {Boehm, B. W.},
  date = {1988-05},
  journaltitle = {Computer},
  volume = {21},
  number = {5},
  pages = {61--72},
  issn = {0018-9162},
  doi = {10.1109/2.59},
  url = {http://ieeexplore.ieee.org/document/59/},
  urldate = {2023-10-18},
  langid = {english},
  file = {/home/jon/Zotero/storage/5DUXDK4T/Boehm - 1988 - A spiral model of software development and enhance.pdf}
}

@article{buddeWhatPrototyping1992,
  title = {What Is Prototyping?},
  author = {Budde, Reinhard and Kautz, Karlheinz and Kuhlenkamp, Karin and Züllighoven, Heinz},
  date = {1992-01-01},
  journaltitle = {Information Technology \& People},
  volume = {6},
  number = {2/3},
  pages = {89--95},
  publisher = {{MCB UP Ltd}},
  issn = {0959-3845},
  doi = {10.1108/EUM0000000003546},
  url = {https://doi.org/10.1108/EUM0000000003546},
  urldate = {2023-10-02},
  abstract = {Explains and defines prototyping in terms of its character, actors and types. Examines four aspects: its use in the software development process, its goals, horizontal and vertical and the relationship between prototype and application system. Clarifies the distinction between breadboard and prototype.},
  keywords = {Management information systems,Prototyping},
  file = {/home/jon/Zotero/storage/AYPIBGZ5/Budde et al. - 1992 - What is prototyping.pdf}
}

@inproceedings{bzeznikNixHPCPackage2017,
  title = {Nix as {{HPC}} Package Management System},
  booktitle = {Proceedings of the {{Fourth International Workshop}} on {{HPC User Support Tools}}},
  author = {Bzeznik, Bruno and Henriot, Oliver and Reis, Valentin and Richard, Olivier and Tavard, Laure},
  date = {2017-11-12},
  series = {{{HUST}}'17},
  pages = {1--6},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/3152493.3152556},
  url = {https://dl.acm.org/doi/10.1145/3152493.3152556},
  urldate = {2023-10-03},
  abstract = {Modern High Performance Computing systems are becoming larger and more heterogeneous. The proper management of software for the users of such systems poses a significant challenge. These users run very diverse applications that may be compiled with proprietary tools for specialized hardware. Moreover, the application life-cycle of these software may exceed the lifetime of the HPC systems themselves. These difficulties motivate the use of specialized package management systems. In this paper, we outline an approach to HPC package development, deployment, management, sharing, and reuse based on the Nix functional package manager. We report our experience with this approach inside the GRICAD HPC center[GRICAD 2017a] in Grenoble over a 12 month period and compare it to other existing approaches.},
  isbn = {978-1-4503-5130-0},
  keywords = {High Performance Computing,Nix,Package Management System},
  file = {/home/jon/Zotero/storage/24FY2CY2/Bzeznik et al. - 2017 - Nix as HPC package management system.pdf}
}

@inproceedings{canonCasePortabilityReproducibility2019,
  title = {A {{Case}} for {{Portability}} and {{Reproducibility}} of {{HPC Containers}}},
  booktitle = {2019 {{IEEE}}/{{ACM International Workshop}} on {{Containers}} and {{New Orchestration Paradigms}} for {{Isolated Environments}} in {{HPC}} ({{CANOPIE-HPC}})},
  author = {Canon, Richard S. and Younge, Andrew},
  date = {2019-11},
  pages = {49--54},
  publisher = {{IEEE}},
  location = {{Denver, CO, USA}},
  doi = {10.1109/CANOPIE-HPC49598.2019.00012},
  url = {https://ieeexplore.ieee.org/document/8950982/},
  urldate = {2023-10-04},
  abstract = {Containerized computing is quickly changing the landscape for the development and deployment of many HPC applications. Containers are able to lower the barrier of entry for emerging workloads to leverage supercomputing resources. However, containers are no silver bullet for deploying HPC software and there are several challenges ahead in which the community must address to ensure container workloads can be reproducible and inter-operable.},
  eventtitle = {2019 {{IEEE}}/{{ACM International Workshop}} on {{Containers}} and {{New Orchestration Paradigms}} for {{Isolated Environments}} in {{HPC}} ({{CANOPIE-HPC}})},
  isbn = {978-1-72816-028-3},
  langid = {english},
  file = {/home/jon/Zotero/storage/4U4A7U8C/Canon and Younge - 2019 - A Case for Portability and Reproducibility of HPC .pdf}
}

@inproceedings{canonCasePortabilityReproducibility2019a,
  title = {A {{Case}} for {{Portability}} and {{Reproducibility}} of {{HPC Containers}}},
  booktitle = {2019 {{IEEE}}/{{ACM International Workshop}} on {{Containers}} and {{New Orchestration Paradigms}} for {{Isolated Environments}} in {{HPC}} ({{CANOPIE-HPC}})},
  author = {Canon, Richard S. and Younge, Andrew},
  date = {2019-11},
  pages = {49--54},
  doi = {10.1109/CANOPIE-HPC49598.2019.00012},
  url = {https://ieeexplore.ieee.org/abstract/document/8950982},
  urldate = {2023-10-04},
  abstract = {Containerized computing is quickly changing the landscape for the development and deployment of many HPC applications. Containers are able to lower the barrier of entry for emerging workloads to leverage supercomputing resources. However, containers are no silver bullet for deploying HPC software and there are several challenges ahead in which the community must address to ensure container workloads can be reproducible and inter-operable. In this paper, we discuss several challenges in utilizing containers for HPC applications and the current approaches used in many HPC container runtimes. These approaches have been proven to enable high-performance execution of containers at scale with the appropriate runtimes. However, the use of these techniques are still ad hoc, test the limits of container workload portability, and several gaps likely remain. We discuss those remaining gaps and propose several potential solutions, including custom container label tagging and runtime hooks as a first step in managing HPC system library complexity.},
  eventtitle = {2019 {{IEEE}}/{{ACM International Workshop}} on {{Containers}} and {{New Orchestration Paradigms}} for {{Isolated Environments}} in {{HPC}} ({{CANOPIE-HPC}})},
  file = {/home/jon/Zotero/storage/F2GCRHJ8/Canon and Younge - 2019 - A Case for Portability and Reproducibility of HPC .pdf;/home/jon/Zotero/storage/GKLSSHWY/8950982.html}
}

@article{carrPrototypingSoftwareDevelopment,
  title = {Prototyping and {{Software Development Approaches}}},
  author = {Carr, Mahil},
  abstract = {Researchers have provided a number of different definitions, process models and classificatory schemes for both prototypes and prototyping approaches over the past two decades. Because there tends to be some confusion in the use of prototyping terms, in this review we attempt to place prototyping in context and delineate evolutionary prototyping approaches from other kinds development approaches that may have prototypes and prototyping strategies embedded within them. We consider what prototypes are, what the prototyping process is, and how software development approaches adopt prototyping for exploration, experiment or evolution. We provide a classification of the software development approaches that include prototyping of some kind. Within this discussion we review experimental prototyping, exploratory prototyping and evolutionary development.},
  langid = {english},
  file = {/home/jon/Zotero/storage/CZZX8Q52/Carr - Prototyping and Software Development Approaches.pdf}
}

@article{carrPrototypingSoftwareDevelopmenta,
  title = {Prototyping and {{Software Development Approaches}}},
  author = {Carr, Mahil},
  abstract = {Researchers have provided a number of different definitions, process models and classificatory schemes for both prototypes and prototyping approaches over the past two decades. Because there tends to be some confusion in the use of prototyping terms, in this review we attempt to place prototyping in context and delineate evolutionary prototyping approaches from other kinds development approaches that may have prototypes and prototyping strategies embedded within them. We consider what prototypes are, what the prototyping process is, and how software development approaches adopt prototyping for exploration, experiment or evolution. We provide a classification of the software development approaches that include prototyping of some kind. Within this discussion we review experimental prototyping, exploratory prototyping and evolutionary development.},
  langid = {english},
  file = {/home/jon/Zotero/storage/3HJHXJG5/Carr - Prototyping and Software Development Approaches.pdf}
}

@article{carrPrototypingSoftwareDevelopmentb,
  title = {Prototyping and {{Software Development Approaches}}},
  author = {Carr, Mahil},
  abstract = {Researchers have provided a number of different definitions, process models and classificatory schemes for both prototypes and prototyping approaches over the past two decades. Because there tends to be some confusion in the use of prototyping terms, in this review we attempt to place prototyping in context and delineate evolutionary prototyping approaches from other kinds development approaches that may have prototypes and prototyping strategies embedded within them. We consider what prototypes are, what the prototyping process is, and how software development approaches adopt prototyping for exploration, experiment or evolution. We provide a classification of the software development approaches that include prototyping of some kind. Within this discussion we review experimental prototyping, exploratory prototyping and evolutionary development.},
  langid = {english},
  file = {/home/jon/Zotero/storage/3A8S42C2/Carr - Prototyping and Software Development Approaches.pdf}
}

@article{carrPrototypingSoftwareDevelopmentc,
  title = {Prototyping and {{Software Development Approaches}}},
  author = {Carr, Mahil},
  abstract = {Researchers have provided a number of different definitions, process models and classificatory schemes for both prototypes and prototyping approaches over the past two decades. Because there tends to be some confusion in the use of prototyping terms, in this review we attempt to place prototyping in context and delineate evolutionary prototyping approaches from other kinds development approaches that may have prototypes and prototyping strategies embedded within them. We consider what prototypes are, what the prototyping process is, and how software development approaches adopt prototyping for exploration, experiment or evolution. We provide a classification of the software development approaches that include prototyping of some kind. Within this discussion we review experimental prototyping, exploratory prototyping and evolutionary development.},
  langid = {english},
  file = {/home/jon/Zotero/storage/73VJ92ZQ/Carr - Prototyping and Software Development Approaches.pdf}
}

@online{CephIoHome,
  title = {Ceph.Io — {{Home}}},
  url = {https://ceph.io/en/},
  urldate = {2023-10-22},
  abstract = {Ceph is an open source distributed storage system designed to evolve with data.},
  langid = {english},
  file = {/home/jon/Zotero/storage/BB7A9BE2/en.html}
}

@software{ChapellangChapelProductive,
  title = {Chapel-Lang/Chapel: A {{Productive Parallel Programming Language}}},
  shorttitle = {Chapel-Lang},
  url = {https://github.com/chapel-lang/chapel},
  urldate = {2023-10-23},
  file = {/home/jon/Zotero/storage/IAZUIZGL/chapel.html}
}

@online{ClusterNetworking,
  title = {Cluster {{Networking}}},
  url = {https://kubernetes.io/docs/concepts/cluster-administration/networking/},
  urldate = {2023-10-18},
  abstract = {Networking is a central part of Kubernetes, but it can be challenging to understand exactly how it is expected to work. There are 4 distinct networking problems to address: Highly-coupled container-to-container communications: this is solved by Pods and localhost communications. Pod-to-Pod communications: this is the primary focus of this document. Pod-to-Service communications: this is covered by Services. External-to-Service communications: this is also covered by Services. Kubernetes is all about sharing machines between applications.},
  langid = {english},
  organization = {{Kubernetes}},
  file = {/home/jon/Zotero/storage/JYPWQNLU/networking.html}
}

@video{computerphileApacheSparkComputerphile2018,
  entrysubtype = {video},
  title = {Apache {{Spark}} - {{Computerphile}}},
  editor = {{Computerphile}},
  editortype = {director},
  date = {2018-12-12},
  url = {https://www.youtube.com/watch?v=tDVPcqGpEnM},
  urldate = {2023-10-02},
  abstract = {Analysing big data stored on a cluster is not easy. Spark allows you to do so much more than just MapReduce. Rebecca Tickle takes us through some code.  https://www.facebook.com/computerphile https://twitter.com/computer\_phile This video was filmed and edited by Sean Riley. Computer Science at the University of Nottingham: https://bit.ly/nottscomputer Computerphile is a sister project to Brady Haran's Numberphile. More at http://www.bradyharan.com}
}

@video{computerphileMapReduceComputerphile2018,
  entrysubtype = {video},
  title = {{{MapReduce}} - {{Computerphile}}},
  editor = {{Computerphile}},
  editortype = {director},
  date = {2018-04-12},
  url = {https://www.youtube.com/watch?v=cvhKoniK5Uo},
  urldate = {2023-10-02},
  abstract = {Peforming operations in parallel on big data. Rebecca Tickle explains MapReduce.  https://www.facebook.com/computerphile https://twitter.com/computer\_phile This video was filmed and edited by Sean Riley. Computer Science at the University of Nottingham: https://bit.ly/nottscomputer Computerphile is a sister project to Brady Haran's Numberphile. More at http://www.bradyharan.com}
}

@online{CreatingClusterKubeadm,
  title = {Creating a Cluster with Kubeadm},
  url = {https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/},
  urldate = {2023-10-18},
  abstract = {Using kubeadm, you can create a minimum viable Kubernetes cluster that conforms to best practices. In fact, you can use kubeadm to set up a cluster that will pass the Kubernetes Conformance tests. kubeadm also supports other cluster lifecycle functions, such as bootstrap tokens and cluster upgrades. The kubeadm tool is good if you need: A simple way for you to try out Kubernetes, possibly for the first time. A way for existing users to automate setting up a cluster and test their application.},
  langid = {english},
  organization = {{Kubernetes}},
  file = {/home/jon/Zotero/storage/ZNSAEZL6/create-cluster-kubeadm.html}
}

@online{CreatingClusterKubeadma,
  title = {Creating a Cluster with Kubeadm},
  url = {https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/},
  urldate = {2023-10-18},
  abstract = {Using kubeadm, you can create a minimum viable Kubernetes cluster that conforms to best practices. In fact, you can use kubeadm to set up a cluster that will pass the Kubernetes Conformance tests. kubeadm also supports other cluster lifecycle functions, such as bootstrap tokens and cluster upgrades. The kubeadm tool is good if you need: A simple way for you to try out Kubernetes, possibly for the first time. A way for existing users to automate setting up a cluster and test their application.},
  langid = {english},
  organization = {{Kubernetes}},
  file = {/home/jon/Zotero/storage/IMD95J3H/create-cluster-kubeadm.html}
}

@online{DockerFAQsDocker2021,
  title = {Docker {{FAQs}} | {{Docker}}},
  date = {2021-12-10T11:45:03-08:00},
  url = {https://www.docker.com/pricing/faq/},
  urldate = {2023-10-18},
  abstract = {Find answers to the most frequently asked questions about Docker pricing, licensing, commercial use, and more.},
  langid = {american},
  file = {/home/jon/Zotero/storage/FYNX43EZ/faq.html}
}

@online{DockerTermsService2022,
  title = {Docker {{Terms}} of {{Service}} | {{Docker}}},
  date = {2022-01-25T16:39:34-08:00},
  url = {https://www.docker.com/legal/docker-terms-service/},
  urldate = {2023-10-18},
  abstract = {Review the Docker Terms of Service for detailed specifics on privacy, restrictions, fees, copyright policy, and more.},
  langid = {american},
  file = {/home/jon/Zotero/storage/XIQKYSSX/docker-terms-service.html}
}

@article{dubeFutureHPCInternet2021,
  title = {Future of {{HPC}}: {{The Internet}} of {{Workflows}}},
  shorttitle = {Future of {{HPC}}},
  author = {Dube, Nicolas and Roweth, Duncan and Faraboschi, Paolo and Milojicic, Dejan},
  date = {2021-09},
  journaltitle = {IEEE Internet Computing},
  volume = {25},
  number = {5},
  pages = {26--34},
  issn = {1941-0131},
  doi = {10.1109/MIC.2021.3103236},
  abstract = {Driven by convergence with artificial intelligence and data analytics, increased heterogeneity, and a hybrid cloud/on-premise delivery model, dynamic composition of workflows will be a key design criteria of future high-performance computing (HPC) systems. While tightly coupled HPC workloads will continue to execute on dedicated supercomputers, other jobs will run elsewhere, including public clouds, and at the edge. Connecting these distributed computing tasks into coherent applications that can perform at scale is what we call “Internet of Workflows.”},
  eventtitle = {{{IEEE Internet Computing}}},
  keywords = {Cloud computing,Computational modeling,Convergence,Data analysis,Data models,High performance computing,Software,Supercomputers},
  file = {/home/jon/Zotero/storage/YWK8E86B/Dube et al. - 2021 - Future of HPC The Internet of Workflows.pdf;/home/jon/Zotero/storage/5VV4WTBU/stamp.html}
}

@article{duboisWhyJohnnyCan2003,
  title = {Why {{Johnny}} Can't Build [Portable Scientific Software]},
  author = {Dubois, P.F. and Epperly, T. and Kumfert, G.},
  date = {2003-09},
  journaltitle = {Computing in Science \& Engineering},
  volume = {5},
  number = {5},
  pages = {83--88},
  issn = {1558-366X},
  doi = {10.1109/MCISE.2003.1225867},
  url = {https://ieeexplore.ieee.org/abstract/document/1225867},
  urldate = {2023-10-03},
  abstract = {The title of this article refers to Rudolph Flesch's famous 1955 book, "Why Johnny Can't Read", which called attention to a nationwide decline in reading ability. Here, the author wants to talk about another situation in which an important ability is lacking: the ability to create significant, portable scientific software. The author discusses some of the reasons this problem exists and suggests some approaches to solving it that seem promising.},
  eventtitle = {Computing in {{Science}} \& {{Engineering}}},
  file = {/home/jon/Zotero/storage/ZW2VL9QH/Dubois et al. - 2003 - Why Johnny can't build [portable scientific softwa.pdf}
}

@article{eckerthHASPHPCApplications,
  title = {{{HASP}}: An {{HPC Applications Services Platform}} for {{Data Analysts}}},
  author = {Eckerth, Jon and Kuno, Harumi and Singhal, Sharad and Byrne, John and Dwaraki, Abhishek and Serebryakov, Sergey},
  abstract = {High Performance Computing (HPC) frameworks make it possible to write large scale, complex, interwoven parallel programs involving intensive inter-process communication. Pachyderm is a very effective tool that simplifies the process of implementing scalable, reproducible and resilient data pipelines. To data analysts, the ability to operate and interactively analyze and reproduce hyper-scale data pipelines is invaluable. To this end, we are building a proof-of-concept programming framework that empowers a HPC framework with reproducible and resilient data pipelines. This allows a catalog of datasets and functions that operate on them to be exposed, enabling data analysts to create, publish, share, and reuse workflows and new datasets seamlessly with low overhead.},
  langid = {english},
  file = {/home/jon/Zotero/storage/SU4LPITE/Eckerth et al. - HASP an HPC Applications Services Platform for Da.pdf}
}

@online{eckerthInstallationInstructionsMinikube,
  title = {Installation Instructions {{Minikube Commit}} 69a05a755facc8d387e031ff5991c20d46dbe4b6},
  shorttitle = {Instuctions {{Minikube Env}}},
  author = {Eckerth, Jon},
  url = {https://github.com/Jo-Eck/ProjectPaper-2/tree/69a05a755facc8d387e031ff5991c20d46dbe4b6/project/Pachyderm},
  urldate = {2023-10-18},
  file = {/home/jon/Zotero/storage/PIV26786/Pachyderm.html}
}

@article{egwutuohaSurveyFaultTolerance2013,
  title = {A Survey of Fault Tolerance Mechanisms and Checkpoint/Restart Implementations for High Performance Computing Systems},
  author = {Egwutuoha, Ifeanyi P. and Levy, David and Selic, Bran and Chen, Shiping},
  date = {2013-09-01},
  journaltitle = {J Supercomput},
  volume = {65},
  number = {3},
  pages = {1302--1326},
  issn = {1573-0484},
  doi = {10.1007/s11227-013-0884-0},
  url = {https://doi.org/10.1007/s11227-013-0884-0},
  urldate = {2023-10-03},
  abstract = {In recent years, High Performance Computing (HPC) systems have been shifting from expensive massively parallel architectures to clusters of commodity PCs to take advantage of cost and performance benefits. Fault tolerance in such systems is a growing concern for long-running applications. In this paper, we briefly review the failure rates of HPC systems and also survey the fault tolerance approaches for HPC systems and issues with these approaches. Rollback-recovery techniques which are most often used for long-running applications on HPC clusters are discussed because they are widely used for long-running applications on HPC systems. Specifically, the feature requirements of rollback-recovery are discussed and a taxonomy is developed for over twenty popular checkpoint/restart solutions. The intent of this paper is to aid researchers in the domain as well as to facilitate development of new checkpointing solutions.},
  langid = {english},
  keywords = {Checkpoint/restart,Clusters,Fault tolerance,High Performance Computing (HPC),Performance,Reliability},
  file = {/home/jon/Zotero/storage/Y6WW7RNX/Egwutuoha et al. - 2013 - A survey of fault tolerance mechanisms and checkpo.pdf}
}

@online{ExploreNetworkPlugins,
  title = {Explore Network Plugins for {{Kubernetes}}: {{CNI}} Explained | {{TechTarget}}},
  shorttitle = {Explore Network Plugins for {{Kubernetes}}},
  url = {https://www.techtarget.com/searchitoperations/tip/Explore-network-plugins-for-Kubernetes-CNI-explained},
  urldate = {2023-10-19},
  abstract = {Learn what CNI is, understand its relationship to Kubernetes and compare the features of different CNI plugins, including Calico, Flannel and Weave.},
  langid = {english},
  organization = {{IT Operations}},
  file = {/home/jon/Zotero/storage/JWZFHUNH/Explore-network-plugins-for-Kubernetes-CNI-explained.html}
}

@online{FabricAttachedMemory,
  title = {Fabric {{Attached Memory}} – {{Hardware}} and {{Software Architecture}} | {{SNIA}}},
  url = {https://www.snia.org/educational-library/fabric-attached-memory-%E2%80%93-hardware-and-software-architecture-2023},
  urldate = {2023-06-29},
  file = {/home/jon/Zotero/storage/7KSBFQH6/fabric-attached-memory-–-hardware-and-software-architecture-2023.html}
}

@online{FichtnerArbeitsmaterial,
  title = {Fichtner\_{{OR}}: {{Arbeitsmaterial}}},
  url = {https://elearning.dhbw-stuttgart.de/moodle/course/resources.php?id=5585},
  urldate = {2023-07-03},
  file = {/home/jon/Zotero/storage/K3N8SYUK/resources.html}
}

@software{Flannel2023,
  title = {Flannel},
  date = {2023-10-19T07:52:55Z},
  origdate = {2014-07-10T17:45:29Z},
  url = {https://github.com/flannel-io/flannel},
  urldate = {2023-10-19},
  abstract = {flannel is a network fabric for containers, designed for Kubernetes},
  organization = {{flannel-io}},
  keywords = {docker,docker-image,flannel,go,kubernetes,network,overlay-network,subnet}
}

@online{FlannelInstallConfig,
  title = {Flannel Install Config},
  url = {https://github.com/flannel-io/flannel/blob/master/Documentation/kube-flannel.yml},
  urldate = {2023-10-19},
  file = {/home/jon/Zotero/storage/WIWQ5YWL/kube-flannel.html}
}

@article{fulopIntroductionDecisionMaking,
  title = {Introduction to {{Decision Making Methods}}},
  author = {Fülöp, János},
  langid = {english},
  file = {/home/jon/Zotero/storage/GT2VQ2WR/Fülöp - Introduction to Decision Making Methods.pdf}
}

@inproceedings{fulopIntroductionDecisionMaking2005,
  title = {Introduction to Decision Making Methods},
  booktitle = {{{BDEI-3}} Workshop, {{Washington}}},
  author = {Fülöp, János},
  date = {2005},
  pages = {1--15},
  url = {https://www.academia.edu/download/43447287/decisionmakingmethods.pdf},
  urldate = {2023-10-12},
  file = {/home/jon/Zotero/storage/L2ED3ZZ6/Fülöp - 2005 - Introduction to decision making methods.pdf}
}

@inproceedings{gamblinSpackPackageManager2015,
  title = {The {{Spack}} Package Manager: Bringing Order to {{HPC}} Software Chaos},
  shorttitle = {The {{Spack}} Package Manager},
  booktitle = {Proceedings of the {{International Conference}} for {{High Performance Computing}}, {{Networking}}, {{Storage}} and {{Analysis}}},
  author = {Gamblin, Todd and LeGendre, Matthew and Collette, Michael R. and Lee, Gregory L. and Moody, Adam and family=Supinski, given=Bronis R., prefix=de, useprefix=true and Futral, Scott},
  date = {2015-11-15},
  series = {{{SC}} '15},
  pages = {1--12},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/2807591.2807623},
  url = {https://dl.acm.org/doi/10.1145/2807591.2807623},
  urldate = {2023-10-03},
  abstract = {Large HPC centers spend considerable time supporting software for thousands of users, but the complexity of HPC software is quickly outpacing the capabilities of existing software management tools. Scientific applications require specific versions of compilers, MPI, and other dependency libraries, so using a single, standard software stack is infeasible. However, managing many configurations is difficult because the configuration space is combinatorial in size. We introduce Spack, a tool used at Lawrence Livermore National Laboratory to manage this complexity. Spack provides a novel, recursive specification syntax to invoke parametric builds of packages and dependencies. It allows any number of builds to coexist on the same system, and it ensures that installed packages can find their dependencies, regardless of the environment. We show through real-world use cases that Spack supports diverse and demanding applications, bringing order to HPC software chaos.},
  isbn = {978-1-4503-3723-6},
  file = {/home/jon/Zotero/storage/F2XDEKSE/Gamblin et al. - 2015 - The Spack package manager bringing order to HPC s.pdf}
}

@standard{GlobLinuxManual,
  title = {Glob(7) - {{Linux}} Manual Page},
  url = {https://man7.org/linux/man-pages/man7/glob.7.html},
  urldate = {2023-10-23},
  file = {/home/jon/Zotero/storage/MRBPC9TS/glob.7.html}
}

@online{Gluster,
  title = {Gluster},
  url = {https://www.gluster.org/},
  urldate = {2023-10-22},
  file = {/home/jon/Zotero/storage/F57C4QDI/www.gluster.org.html}
}

@inproceedings{guptaEvaluationHPCApplications2011,
  title = {Evaluation of {{HPC Applications}} on {{Cloud}}},
  booktitle = {2011 {{Sixth Open Cirrus Summit}}},
  author = {Gupta, Abhishek and Milojicic, Dejan},
  date = {2011-10},
  pages = {22--26},
  publisher = {{IEEE}},
  location = {{Atlanta, GA, USA}},
  doi = {10.1109/OCS.2011.10},
  url = {http://ieeexplore.ieee.org/document/6200551/},
  urldate = {2023-10-23},
  abstract = {HPC applications are increasingly being used in academia and laboratories for scientific research and in industries for business and analytics. Cloud computing offers the benefits of virtualization, elasticity of resources and elimination of cluster setup cost and time to HPC applications users. However, poor network performance, performance variation and OS noise are some of the challenges for execution of HPC applications on Cloud. In this paper, we propose that Cloud can be viable platform for some HPC applications depending upon application characteristics such as communication volume and pattern and sensitivity to OS noise and scale. We present an evaluation of the performance and cost tradeoffs of HPC applications on a range of platforms varying from Cloud (with and without virtualization) to HPC-optimized cluster. Our results show that Cloud is viable platform for some applications, specifically, non communicationintensive applications such as embarrassingly parallel and tree-structured computations up to high processor count and for communication-intensive applications up to low processor count.},
  eventtitle = {2011 6th {{Open Cirrus Summit}} ({{OCS}})},
  isbn = {978-0-7695-4650-6 978-1-4673-0727-7},
  langid = {english},
  file = {/home/jon/Zotero/storage/CVKHJZQT/Gupta and Milojicic - 2011 - Evaluation of HPC Applications on Cloud.pdf}
}

@incollection{hainesWorkflowOrchestrationApache2022,
  title = {Workflow {{Orchestration}} with {{Apache Airflow}}},
  booktitle = {Modern {{Data Engineering}} with {{Apache Spark}}: {{A Hands-On Guide}} for {{Building Mission-Critical Streaming Applications}}},
  author = {Haines, Scott},
  date = {2022},
  pages = {255--295},
  publisher = {{Springer}},
  file = {/home/jon/Zotero/storage/SJJULDJR/978-1-4842-7452-1_8.html}
}

@book{harenslakDataPipelinesApache2021,
  title = {Data {{Pipelines}} with {{Apache Airflow}}},
  author = {Harenslak, Bas P. and family=Ruiter, given=Julian, prefix=de, useprefix=true},
  date = {2021},
  publisher = {{Simon and Schuster}},
  file = {/home/jon/Zotero/storage/Y3K839KY/books.html}
}

@online{HelmDocsHome,
  title = {Helm {{Docs Home}}},
  url = {https://helm.sh/docs/},
  urldate = {2023-10-18},
  abstract = {Everything you need to know about how the documentation is organized.},
  langid = {american},
  file = {/home/jon/Zotero/storage/VTU6MBQZ/docs.html}
}

@inproceedings{higginsOrchestratingDockerContainers2015,
  title = {Orchestrating {{Docker Containers}} in the {{HPC Environment}}},
  booktitle = {High {{Performance Computing}}},
  author = {Higgins, Joshua and Holmes, Violeta and Venters, Colin},
  editor = {Kunkel, Julian M. and Ludwig, Thomas},
  date = {2015},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {506--513},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-20119-1_36},
  abstract = {Linux container technology has more than proved itself useful in cloud computing as a lightweight alternative to virtualisation, whilst still offering good enough resource isolation. Docker is emerging as a popular runtime for managing Linux containers, providing both management tools and a simple file format. Research into the performance of containers compared to traditional Virtual Machines and bare metal shows that containers can achieve near native speeds in processing, memory and network throughput. A technology born in the cloud, it is making inroads into scientific computing both as a format for sharing experimental applications and as a paradigm for cloud based execution. However, it has unexplored uses in traditional cluster and grid computing. It provides a run time environment in which there is an opportunity for typical cluster and parallel applications to execute at native speeds, whilst being bundled with their own specific (or legacy) library versions and support software. This offers a solution to the Achilles heel of cluster and grid computing that requires the user to hold intimate knowledge of the local software infrastructure. Using Docker brings us a step closer to more effective job and resource management within the cluster by providing both a common definition format and a repeatable execution environment. In this paper we present the results of our work in deploying Docker containers in the cluster environment and an evaluation of its suitability as a runtime for high performance parallel execution. Our findings suggest that containers can be used to tailor the run time environment for an MPI application without compromising performance, and would provide better Quality of Service for users of scientific computing.},
  isbn = {978-3-319-20119-1},
  langid = {english},
  keywords = {Cluster,Docker,Grids,Linux containers,Run time environment}
}

@inproceedings{higginsOrchestratingDockerContainers2015a,
  title = {Orchestrating {{Docker Containers}} in the {{HPC Environment}}},
  booktitle = {High {{Performance Computing}}},
  author = {Higgins, Joshua and Holmes, Violeta and Venters, Colin},
  editor = {Kunkel, Julian M. and Ludwig, Thomas},
  date = {2015},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {506--513},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-20119-1_36},
  abstract = {Linux container technology has more than proved itself useful in cloud computing as a lightweight alternative to virtualisation, whilst still offering good enough resource isolation. Docker is emerging as a popular runtime for managing Linux containers, providing both management tools and a simple file format. Research into the performance of containers compared to traditional Virtual Machines and bare metal shows that containers can achieve near native speeds in processing, memory and network throughput. A technology born in the cloud, it is making inroads into scientific computing both as a format for sharing experimental applications and as a paradigm for cloud based execution. However, it has unexplored uses in traditional cluster and grid computing. It provides a run time environment in which there is an opportunity for typical cluster and parallel applications to execute at native speeds, whilst being bundled with their own specific (or legacy) library versions and support software. This offers a solution to the Achilles heel of cluster and grid computing that requires the user to hold intimate knowledge of the local software infrastructure. Using Docker brings us a step closer to more effective job and resource management within the cluster by providing both a common definition format and a repeatable execution environment. In this paper we present the results of our work in deploying Docker containers in the cluster environment and an evaluation of its suitability as a runtime for high performance parallel execution. Our findings suggest that containers can be used to tailor the run time environment for an MPI application without compromising performance, and would provide better Quality of Service for users of scientific computing.},
  isbn = {978-3-319-20119-1},
  langid = {english},
  keywords = {Cluster,Docker,Grids,Linux containers,Run time environment}
}

@online{Home,
  title = {Home},
  url = {https://airflow.apache.org/},
  urldate = {2023-10-07},
  abstract = {Platform created by the community to programmatically author, schedule and monitor workflows.},
  langid = {english},
  organization = {{Apache Airflow}},
  file = {/home/jon/Zotero/storage/82NVKTU3/airflow.apache.org.html}
}

@online{HomeKnative,
  title = {Home - {{Knative}}},
  url = {https://knative.dev/docs/},
  urldate = {2023-10-07},
  file = {/home/jon/Zotero/storage/SND9E9PL/docs.html}
}

@online{HomePage2022,
  title = {Home {{Page}}},
  date = {2022-07-06T22:56:08+00:00},
  url = {https://www.pachyderm.com/},
  urldate = {2023-10-04},
  abstract = {Data-driven pipelines automatically trigger based on detecting data changes.},
  langid = {american},
  organization = {{Pachyderm}},
  file = {/home/jon/Zotero/storage/5TYVL4H6/www.pachyderm.com.html}
}

@inproceedings{hosteEasyBuildBuildingSoftware2012,
  title = {{{EasyBuild}}: {{Building Software}} with {{Ease}}},
  shorttitle = {{{EasyBuild}}},
  booktitle = {2012 {{SC Companion}}: {{High Performance Computing}}, {{Networking Storage}} and {{Analysis}}},
  author = {Hoste, Kenneth and Timmerman, Jens and Georges, Andy and De Weirdt, Stijn},
  date = {2012-11},
  pages = {572--582},
  doi = {10.1109/SC.Companion.2012.81},
  url = {https://ieeexplore.ieee.org/abstract/document/6495863},
  urldate = {2023-10-03},
  abstract = {Maintaining a collection of software installations for a diverse user base can be a tedious, repetitive, error-prone and time-consuming task. Because most end-user software packages for an HPC environment are not readily available in existing OS package managers, they require significant extra effort from the user support team. Reducing this effort would free up a large amount of time for tackling more urgent tasks. In this work, we present EasyBuild, a software installation framework written in Python that aims to support the various installation procedures used by the vast collection of software packages that are typically installed in an HPC environment - catering to widely different user profiles. It is built on top of existing tools, and provides support for well-established installation procedures. Supporting customised installation procedures requires little effort, and sharing implementations of installation procedures becomes very easy. Installing software packages that are supported can be done by issuing a single command, even if dependencies are not available yet. Hence, it simplifies the task of HPC site support teams, and even allows end-users to keep their software installations consistent and up to date.},
  eventtitle = {2012 {{SC Companion}}: {{High Performance Computing}}, {{Networking Storage}} and {{Analysis}}},
  file = {/home/jon/Zotero/storage/KYS8DCP6/Hoste et al. - 2012 - EasyBuild Building Software with Ease.pdf;/home/jon/Zotero/storage/YPGHB5BZ/6495863.html}
}

@online{HttpsAirflowApache,
  title = {{{https://airflow.apache.org/}}},
  url = {https://airflow.apache.org/},
  urldate = {2023-10-12},
  abstract = {Platform created by the community to programmatically author, schedule and monitor workflows.},
  langid = {english},
  organization = {{Apache Airflow}},
  file = {/home/jon/Zotero/storage/MRJQF2GN/airflow.apache.org.html}
}

@online{incMinIOMinIOKubernetes,
  title = {{{MinIO}} | {{MinIO}} for {{Kubernetes}}},
  author = {Inc, MinIO},
  url = {https://min.io},
  urldate = {2023-10-18},
  langid = {english},
  organization = {{MinIO}},
  file = {/home/jon/Zotero/storage/ZTYJY596/kubernetes.html}
}

@online{InstallingAddonsa,
  title = {Installing {{Addons}}},
  url = {https://kubernetes.io/docs/concepts/cluster-administration/addons/},
  urldate = {2023-10-19},
  abstract = {Note: This section links to third party projects that provide functionality required by Kubernetes. The Kubernetes project authors aren't responsible for these projects, which are listed alphabetically. To add a project to this list, read the content guide before submitting a change. More information. Add-ons extend the functionality of Kubernetes. This page lists some of the available add-ons and links to their respective installation instructions. The list does not try to be exhaustive.},
  langid = {english},
  organization = {{Kubernetes}},
  file = {/home/jon/Zotero/storage/CXP63VQ8/addons.html}
}

@online{InstallingKubeadm,
  title = {Installing Kubeadm},
  url = {https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/},
  urldate = {2023-10-22},
  abstract = {This page shows how to install the kubeadm toolbox. For information on how to create a cluster with kubeadm once you have performed this installation process, see the Creating a cluster with kubeadm page. This installation guide is for Kubernetes v1.28. If you want to use a different Kubernetes version, please refer to the following pages instead: Installing kubeadm (Kubernetes v1.27) Installing kubeadm (Kubernetes v1.26) Installing kubeadm (Kubernetes v1.25) Installing kubeadm (Kubernetes v1.},
  langid = {english},
  organization = {{Kubernetes}},
  file = {/home/jon/Zotero/storage/WCGL25GM/install-kubeadm.html}
}

@online{IntroPipelines2023,
  title = {Intro to {{Pipelines}}},
  date = {2023-01-30T16:17:44-06:00},
  url = {https://docs.pachyderm.com/latest/learn/intro-pipelines/},
  urldate = {2023-10-23},
  abstract = {Learn about the Pipeline System and how to define pipelines in YAML for data transformation and processing, including datums, jobs, and advanced glob patterns.},
  langid = {english},
  file = {/home/jon/Zotero/storage/45D8XURA/intro-pipelines.html}
}

@online{IPaaSSolutionEnterprise,
  title = {{{iPaaS Solution}} for the {{Enterprise}}},
  url = {https://www.snaplogic.com/},
  urldate = {2023-10-07},
  abstract = {SnapLogic's iPaaS platform empowers enterprises by automating application, data and cloud integration. Reach digital business transformation with SnapLogic.},
  langid = {american},
  organization = {{SnapLogic}},
  file = {/home/jon/Zotero/storage/SPKR3P7H/www.snaplogic.com.html}
}

@report{kennyKubernetesHPCAdministration2021,
  title = {Kubernetes for {{HPC Administration}}.},
  author = {Kenny, Joseph and Knight, Samuel},
  date = {2021-09-01},
  number = {SAND2021-11507C},
  institution = {{Sandia National Lab. (SNL-NM), Albuquerque, NM (United States); Sandia National Laboratories, SNL California}},
  url = {https://www.osti.gov/biblio/1887730},
  urldate = {2023-06-29},
  abstract = {Abstract not provided.},
  langid = {english},
  file = {/home/jon/Zotero/storage/H8BAICLF/Kenny and Knight - 2021 - Kubernetes for HPC Administration..pdf}
}

@article{kreuzbergerMachineLearningOperations2023,
  title = {Machine {{Learning Operations}} ({{MLOps}}): {{Overview}}, {{Definition}}, and {{Architecture}}},
  shorttitle = {Machine {{Learning Operations}} ({{MLOps}})},
  author = {Kreuzberger, Dominik and Kühl, Niklas and Hirschl, Sebastian},
  date = {2023},
  journaltitle = {IEEE Access},
  volume = {11},
  pages = {31866--31879},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2023.3262138},
  url = {https://ieeexplore.ieee.org/document/10081336/},
  urldate = {2023-10-04},
  abstract = {The final goal of all industrial machine learning (ML) projects is to develop ML products and rapidly bring them into production. However, it is highly challenging to automate and operationalize ML products and thus many ML endeavors fail to deliver on their expectations. The paradigm of Machine Learning Operations (MLOps) addresses this issue. MLOps includes several aspects, such as best practices, sets of concepts, and development culture. However, MLOps is still a vague term and its consequences for researchers and professionals are ambiguous. To address this gap, we conduct mixed-method research, including a literature review, a tool review, and expert interviews. As a result of these investigations, we contribute to the body of knowledge by providing an aggregated overview of the necessary principles, components, and roles, as well as the associated architecture and workflows. Furthermore, we provide a comprehensive definition of MLOps and highlight open challenges in the field. Finally, this work provides guidance for ML researchers and practitioners who want to automate and operate their ML products with a designated set of technologies.},
  langid = {english},
  file = {/home/jon/Zotero/storage/MG5ZD2ZZ/Kreuzberger et al. - 2023 - Machine Learning Operations (MLOps) Overview, Def.pdf}
}

@online{Kubeflow,
  title = {Kubeflow},
  url = {https://www.kubeflow.org/},
  urldate = {2023-10-07},
  abstract = {Kubeflow makes deployment of ML Workflows on Kubernetes straightforward and automated},
  langid = {english},
  organization = {{Kubeflow}},
  file = {/home/jon/Zotero/storage/38VTYFPY/www.kubeflow.org.html}
}

@online{KubernetesCNIPlugins,
  title = {Kubernetes  {{CNI}} Plugins},
  url = {https://kubernetes.io/docs/concepts/cluster-administration/addons/},
  urldate = {2023-10-19},
  abstract = {Note: This section links to third party projects that provide functionality required by Kubernetes. The Kubernetes project authors aren't responsible for these projects, which are listed alphabetically. To add a project to this list, read the content guide before submitting a change. More information. Add-ons extend the functionality of Kubernetes. This page lists some of the available add-ons and links to their respective installation instructions. The list does not try to be exhaustive.},
  langid = {english},
  organization = {{Kubernetes}},
  file = {/home/jon/Zotero/storage/VK9DSGLE/addons.html}
}

@online{MachineLearningOperations,
  title = {Machine {{Learning Operations}} ({{MLOps}}): {{Overview}}, {{Definition}}, and {{Architecture}} | {{IEEE Journals}} \& {{Magazine}} | {{IEEE Xplore}}},
  url = {https://ieeexplore.ieee.org/abstract/document/10081336},
  urldate = {2023-10-04},
  file = {/home/jon/Zotero/storage/XPQQV6Y4/10081336.html}
}

@book{martinKubernetesPreparingCKA2021,
  title = {Kubernetes: {{Preparing}} for the {{CKA}} and {{CKAD Certifications}}},
  shorttitle = {Kubernetes},
  author = {Martin, Philippe},
  date = {2021},
  publisher = {{Apress}},
  location = {{Berkeley, CA}},
  doi = {10.1007/978-1-4842-6494-2},
  url = {http://link.springer.com/10.1007/978-1-4842-6494-2},
  urldate = {2023-10-18},
  isbn = {978-1-4842-6493-5 978-1-4842-6494-2},
  langid = {english},
  file = {/home/jon/Zotero/storage/4F8XVDJR/Martin - 2021 - Kubernetes Preparing for the CKA and CKAD Certifi.pdf}
}

@online{mehndirattaComparingKubernetesContainer,
  title = {Comparing {{Kubernetes Container Network Interface}} ({{CNI}}) Providers | {{Kubevious}}.Io},
  author = {Mehndiratta, Harshit},
  url = {https://kubevious.io/blog/post/comparing-kubernetes-container-network-interface-cni-providers},
  urldate = {2023-10-19},
  abstract = {Kubernetes being a highly modular open source project, provides a lot of flexibility in network implementation. Many projects have sprung up in the Kubernetes ecosystem, making communication between…},
  langid = {english},
  file = {/home/jon/Zotero/storage/NIV4YRG7/comparing-kubernetes-container-network-interface-cni-providers.html}
}

@inproceedings{merrillArkoudaInteractiveData2019,
  title = {Arkouda: Interactive Data Exploration Backed by {{Chapel}}},
  shorttitle = {Arkouda},
  booktitle = {Proceedings of the {{ACM SIGPLAN}} 6th on {{Chapel Implementers}} and {{Users Workshop}}},
  author = {Merrill, Michael and Reus, William and Neumann, Timothy},
  date = {2019-06-22},
  series = {{{CHIUW}} 2019},
  pages = {28},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/3329722.3330148},
  url = {https://dl.acm.org/doi/10.1145/3329722.3330148},
  urldate = {2023-10-04},
  abstract = {Exploratory data analysis (EDA) is the prerequisite for all data science. EDA is non-negotiably interactive—by far the most popular environment for EDA is a Jupyter notebook—and, as datasets grow, increasingly computationally intensive. Several existing projects attempt to combine interactivity and distributed computation using programming paradigms and tools from cloud computing, but none of these projects have come close to meeting our needs for high-performance EDA. To fill this gap, we have developed a prototype, called arkouda, that allows a user to interactively issue massively parallel computations on distributed data.},
  isbn = {978-1-4503-6800-1},
  keywords = {Chapel,Exploratory data analysis (EDA),Jupyter,NumPy,Python},
  file = {/home/jon/Zotero/storage/QRW9S4AT/Merrill et al. - 2019 - Arkouda interactive data exploration backed by Ch.pdf}
}

@inproceedings{mitchellExplorationWorkflowManagement2019,
  title = {Exploration of {{Workflow Management Systems Emerging Features}} from {{Users Perspectives}}},
  booktitle = {2019 {{IEEE International Conference}} on {{Big Data}} ({{Big Data}})},
  author = {Mitchell, Ryan and Pottier, Loїc and Jacobs, Steve and family=Silva, given=Rafael Ferreira, prefix=da, useprefix=false and Rynge, Mats and Vahi, Karan and Deelman, Ewa},
  date = {2019-12},
  pages = {4537--4544},
  doi = {10.1109/BigData47090.2019.9005494},
  abstract = {There has been a recent emergence of new workflow applications focused on data analytics and machine learning. This emergence has precipitated a change in the workflow management landscape, causing the development of new dataoriented workflow management systems (WMSs) in addition to the earlier standard of task-oriented WMSs. In this paper, we summarize three general workflow use-cases and explore the unique requirements of each use-case in order to understand how WMSs from both workflow management models meet the requirements of each workflow use-case from the user’s perspective. We analyze the applicability of the two models by carefully describing each model and by providing an examination of the different variations of WMSs that fall under the task driven model. To illustrate the strengths and weaknesses of each workflow management model, we summarize the key features of four production-ready WMSs: Pegasus, Makeflow, Apache Airflow, and Pachyderm. To deepen our analysis of the four WMSs examined in this paper,we implement three real-world use-cases to highlight the specifications and features of each WMS. We present our final assessment of each WMS after considering the following factors: usability, performance, ease of deployment, and relevance. The purpose of this work is to offer insights from the user’s perspective into the research challenges that WMSs currently face due to the evolving workflow landscape.},
  eventtitle = {2019 {{IEEE International Conference}} on {{Big Data}} ({{Big Data}})},
  keywords = {Atmospheric modeling,Big Data,Biological system modeling,Computational modeling,Data analysis,Data-driven.,Machine learning,Scientific workflow,Task analysis,Task-driven,Workflow Management System},
  file = {/home/jon/Zotero/storage/SEQSYHKQ/Mitchell et al. - 2019 - Exploration of Workflow Management Systems Emergin.pdf;/home/jon/Zotero/storage/Y3WVEQNM/9005494.html}
}

@article{nikolovConceptualizationScalableExecution2021,
  title = {Conceptualization and Scalable Execution of Big Data Workflows Using Domain-Specific Languages and Software Containers},
  author = {Nikolov, Nikolay and Dessalk, Yared Dejene and Khan, Akif Quddus and Soylu, Ahmet and Matskin, Mihhail and Payberah, Amir H. and Roman, Dumitru},
  date = {2021-12},
  journaltitle = {Internet of Things},
  volume = {16},
  pages = {100440},
  issn = {25426605},
  doi = {10.1016/j.iot.2021.100440},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S2542660521000834},
  urldate = {2023-10-04},
  abstract = {Big Data processing, especially with the increasing proliferation of Internet of Things (IoT) technologies and convergence of IoT, edge and cloud computing technologies, involves handling massive and complex data sets on heterogeneous resources and incorporating different tools, frameworks, and processes to help organizations make sense of their data collected from various sources. This set of operations, referred to as Big Data workflows, requires taking advantage of Cloud infrastructures’ elasticity for scalability. In this article, we present the design and prototype implementation of a Big Data workflow approach based on the use of software container technologies, message-oriented middleware (MOM), and a domain-specific language (DSL) to enable highly scalable workflow execution and abstract workflow definition. We demonstrate our system in a use case and a set of experiments that show the practical applicability of the proposed approach for the specification and scalable execution of Big Data workflows. Furthermore, we compare our proposed approach’s scalability with that of Argo Workflows – one of the most prominent tools in the area of Big Data workflows – and provide a qualitative evaluation of the proposed DSL and overall approach with respect to the existing literature.},
  langid = {english},
  file = {/home/jon/Zotero/storage/5N3N98KA/Nikolov et al. - 2021 - Conceptualization and scalable execution of big da.pdf}
}

@article{nikolovConceptualizationScalableExecution2021a,
  title = {Conceptualization and Scalable Execution of Big Data Workflows Using Domain-Specific Languages and Software Containers},
  author = {Nikolov, Nikolay and Dessalk, Yared Dejene and Khan, Akif Quddus and Soylu, Ahmet and Matskin, Mihhail and Payberah, Amir H. and Roman, Dumitru},
  date = {2021-12-01},
  journaltitle = {Internet of Things},
  volume = {16},
  pages = {100440},
  issn = {2542-6605},
  doi = {10.1016/j.iot.2021.100440},
  url = {https://www.sciencedirect.com/science/article/pii/S2542660521000834},
  urldate = {2023-10-04},
  abstract = {Big Data processing, especially with the increasing proliferation of Internet of Things (IoT) technologies and convergence of IoT, edge and cloud computing technologies, involves handling massive and complex data sets on heterogeneous resources and incorporating different tools, frameworks, and processes to help organizations make sense of their data collected from various sources. This set of operations, referred to as Big Data workflows, requires taking advantage of Cloud infrastructures’ elasticity for scalability. In this article, we present the design and prototype implementation of a Big Data workflow approach based on the use of software container technologies, message-oriented middleware (MOM), and a domain-specific language (DSL) to enable highly scalable workflow execution and abstract workflow definition. We demonstrate our system in a use case and a set of experiments that show the practical applicability of the proposed approach for the specification and scalable execution of Big Data workflows. Furthermore, we compare our proposed approach’s scalability with that of Argo Workflows – one of the most prominent tools in the area of Big Data workflows – and provide a qualitative evaluation of the proposed DSL and overall approach with respect to the existing literature.},
  keywords = {Big data workflows,Domain-specific languages,Internet of Things,Software containers},
  file = {/home/jon/Zotero/storage/V245RD2W/Nikolov et al. - 2021 - Conceptualization and scalable execution of big da.pdf;/home/jon/Zotero/storage/SC7YEDJX/S2542660521000834.html}
}

@article{novellaContainerbasedBioinformaticsPachyderm2019,
  title = {Container-Based Bioinformatics with {{Pachyderm}}},
  author = {Novella, Jon Ander and Emami Khoonsari, Payam and Herman, Stephanie and Whitenack, Daniel and Capuccini, Marco and Burman, Joachim and Kultima, Kim and Spjuth, Ola},
  editor = {Wren, Jonathan},
  date = {2019-03-01},
  journaltitle = {Bioinformatics},
  volume = {35},
  number = {5},
  pages = {839--846},
  issn = {1367-4803, 1367-4811},
  doi = {10.1093/bioinformatics/bty699},
  url = {https://academic.oup.com/bioinformatics/article/35/5/839/5068160},
  urldate = {2023-06-29},
  abstract = {Motivation: Computational biologists face many challenges related to data size, and they need to manage complicated analyses often including multiple stages and multiple tools, all of which must be deployed to modern infrastructures. To address these challenges and maintain reproducibility of results, researchers need (i) a reliable way to run processing stages in any computational environment, (ii) a well-defined way to orchestrate those processing stages and (iii) a data management layer that tracks data as it moves through the processing pipeline.},
  langid = {english},
  file = {/home/jon/Zotero/storage/C5LF9253/Novella et al. - 2019 - Container-based bioinformatics with Pachyderm.pdf}
}

@online{PachydermDocsLocal,
  title = {Pachyderm {{Docs}} - {{Local Deploy}}},
  url = {https://docs.pachyderm.com/2.6.x/set-up/local-deploy/},
  urldate = {2023-10-18},
  abstract = {Learn how to install locally using your favorite container solution.},
  langid = {english},
  organization = {{Pachyderm Docs - Local Deploy}},
  file = {/home/jon/Zotero/storage/5J8ST977/local-deploy.html}
}

@online{PachydermDocsOnPrem,
  type = {Documentation},
  title = {Pachyderm {{Docs}} - {{On-Prem Deploy}}},
  url = {https://docs.pachyderm.com/latest/set-up/on-prem/},
  urldate = {2023-10-18},
  abstract = {Learn how to install on your premises.},
  langid = {english},
  organization = {{Pachyderm Docs - On-Prem Deploy}},
  file = {/home/jon/Zotero/storage/T52QUHZ5/on-prem.html}
}

@online{pachydermGithubPachyderm,
  type = {Code repository},
  title = {Github {{Pachyderm}}},
  author = {{pachyderm}},
  url = {https://github.com/pachyderm/pachyderm},
  urldate = {2023-10-04},
  organization = {{Github repository}},
  file = {/home/jon/Zotero/storage/W96EDFF5/pachyderm.html}
}

@article{robertsWeightApproximationsMultiattribute2002,
  title = {Weight Approximations in Multi-Attribute Decision Models},
  author = {Roberts, Ron and Goodwin, Paul},
  date = {2002},
  journaltitle = {Journal of Multi-Criteria Decision Analysis},
  volume = {11},
  number = {6},
  pages = {291--303},
  issn = {1099-1360},
  doi = {10.1002/mcda.320},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mcda.320},
  urldate = {2023-10-16},
  abstract = {The use of surrogate weights based on rankings has been proposed as a method for avoiding difficulties associated with the elicitation of weights in multi-attribute decision analysis. When the simple multiattribute rating technique using swings (SMARTS) method is being employed it has been suggested that rank order centroid (ROC) weights are the best surrogate weights to use. This study shows that ROC weights are appropriate to use as a substitute for original weights that are constrained to sum to a fixed total (usually 1 or 100) as used in the point allocation method. If, however, the original weights are determined without any initial restrictions, as in the direct rating method, and are then normalized, which is the common procedure in SMARTS analysis, then the ROC weights do not provide the best approximations to the original weights. This paper shows how to obtain rank order distribution (ROD) weights that provide a better approximation than the ROC approach to unrestricted original weights. The paper also shows that, as the number of attributes in a decision problem increases, the ROD weights approximate to the more easily calculated rank sum weights. Copyright © 2003 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {multi-criteria decision making,rank order centroid weights,weight elicitation},
  file = {/home/jon/Zotero/storage/WJYB4YQF/mcda.html}
}

@article{robertsWeightApproximationsMultiattribute2002a,
  title = {Weight Approximations in Multi-Attribute Decision Models},
  author = {Roberts, Ron and Goodwin, Paul},
  date = {2002},
  journaltitle = {Journal of Multi-Criteria Decision Analysis},
  volume = {11},
  number = {6},
  pages = {291--303},
  issn = {1099-1360},
  doi = {10.1002/mcda.320},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mcda.320},
  urldate = {2023-10-16},
  abstract = {The use of surrogate weights based on rankings has been proposed as a method for avoiding difficulties associated with the elicitation of weights in multi-attribute decision analysis. When the simple multiattribute rating technique using swings (SMARTS) method is being employed it has been suggested that rank order centroid (ROC) weights are the best surrogate weights to use. This study shows that ROC weights are appropriate to use as a substitute for original weights that are constrained to sum to a fixed total (usually 1 or 100) as used in the point allocation method. If, however, the original weights are determined without any initial restrictions, as in the direct rating method, and are then normalized, which is the common procedure in SMARTS analysis, then the ROC weights do not provide the best approximations to the original weights. This paper shows how to obtain rank order distribution (ROD) weights that provide a better approximation than the ROC approach to unrestricted original weights. The paper also shows that, as the number of attributes in a decision problem increases, the ROD weights approximate to the more easily calculated rank sum weights. Copyright © 2003 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {multi-criteria decision making,rank order centroid weights,weight elicitation},
  file = {/home/jon/Zotero/storage/64DL4RUG/Roberts and Goodwin - 2002 - Weight approximations in multi-attribute decision .pdf;/home/jon/Zotero/storage/3VWUVJQE/mcda.html}
}

@online{Rook,
  title = {Rook},
  url = {https://rook.io/},
  urldate = {2023-10-22},
  file = {/home/jon/Zotero/storage/D3QNZLHS/rook.io.html}
}

@article{rufDemystifyingMLOpsPresenting2021,
  title = {Demystifying {{MLOps}} and {{Presenting}} a {{Recipe}} for the {{Selection}} of {{Open-Source Tools}}},
  author = {Ruf, Philipp and Madan, Manav and Reich, Christoph and Ould-Abdeslam, Djaffar},
  date = {2021-01},
  journaltitle = {Applied Sciences},
  volume = {11},
  number = {19},
  pages = {8861},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2076-3417},
  doi = {10.3390/app11198861},
  url = {https://www.mdpi.com/2076-3417/11/19/8861},
  urldate = {2023-10-04},
  abstract = {Nowadays, machine learning projects have become more and more relevant to various real-world use cases. The success of complex Neural Network models depends upon many factors, as the requirement for structured and machine learning-centric project development management arises. Due to the multitude of tools available for different operational phases, responsibilities and requirements become more and more unclear. In this work, Machine Learning Operations (MLOps) technologies and tools for every part of the overall project pipeline, as well as involved roles, are examined and clearly defined. With the focus on the inter-connectivity of specific tools and comparison by well-selected requirements of MLOps, model performance, input data, and system quality metrics are briefly discussed. By identifying aspects of machine learning, which can be reused from project to project, open-source tools which help in specific parts of the pipeline, and possible combinations, an overview of support in MLOps is given. Deep learning has revolutionized the field of Image processing, and building an automated machine learning workflow for object detection is of great interest for many organizations. For this, a simple MLOps workflow for object detection with images is portrayed.},
  issue = {19},
  langid = {english},
  keywords = {MlOps,quality metrics,tool comparison,workflow automation},
  file = {/home/jon/Zotero/storage/4BS96SWB/Ruf et al. - 2021 - Demystifying MLOps and Presenting a Recipe for the.pdf}
}

@article{sayersCLoudApplicationServices2015,
  title = {{{CLoud Application Services Platform}}},
  author = {Sayers, Craig and Laffitte, Hernan and Reddy, Prakash and Ozonat, Kivanc and Sayal, Mehmet and Simitsis, Alkis and Singhal, Sharad and Koutrika, Georgia and Das, Mahashweta and Aji, Ablimit and Bosamiya, Hitesh Amrutlal and Riss, Marcelo and Wilkinson, Kevin},
  date = {2015},
  langid = {english},
  file = {/home/jon/Zotero/storage/PN7ADPIX/Sayers et al. - 2015 - CLoud Application Services Platform.pdf}
}

@article{sayersCloudApplicationServices2015,
  title = {Cloud {{Application Services Platform}} ({{CLASP}}): {{User}} Guide, Introduction, and Operation},
  shorttitle = {Cloud {{Application Services Platform}} ({{CLASP}})},
  author = {Sayers, C. and Laffitte, H. and Reddy, P. and Ozonat, K. and Sayal, M. and Simitsis, A. and Singhal, Sharad and Koutrika, Georgia and Das, M. and Aji, A. and Bosamiya, H.A. and Riss, Marcelo and Wilkinson, Kevin and Lucio, J.C.O. and Cantal, A.G.S. and Carvalho, C.R.M.},
  date = {2015-06-11},
  pages = {1--60},
  abstract = {Software developers at large tech companies spend a lot of time writing code for tasks that colleagues elsewhere in the organization have already addressed. Scripts are rarely written or documented with discovery in mind, and the APIs on which they depend are frequently inconsistent, further limiting reuse. For mobile devices the App Catalog serves as an essential intermediary, streamlining the process both for developers and end users. We've created an experimental platform called CLASP (Cloud Application Services Platform) applying that model by publishing services and datasets instead of apps. It includes support for existing APIs, and we've also created an SDK (software development kit), so our users can write other operations themselves and easily publish in the catalog for later discovery and reuse. CLASP allows us to take a very diverse set of operations and make them all available through a consistent compositional interface. For example, you can retrieve log messages using OneView and analyze the text using Autonomy, or gather system configuration using iLO interfaces and persist the results in a Vertica Database. Our internal deployment now has more than 2,000 services, and has been used by more than 150 developers. It allows application developers to discover, test, and use services while providing a seamless app-catalog-type experience for service developers, allowing them to code and test locally while semi-automating the process of publishing those in the catalog. Developed by HP Labs, CLASP is an experimental platform and not a product. This report includes an introduction, quick-start guide, and implementational details.}
}

@article{schmidtEvaluationDataScience,
  title = {Evaluation von Data Science Workflow Engines für Kubernetes},
  author = {Schmidt, David},
  langid = {ngerman},
  file = {/home/jon/Zotero/storage/NJMEJZQJ/Schmidt - Evaluation von Data Science Workflow Engines für K.pdf}
}

@online{SimpleMultiAttributeRating,
  title = {Simple {{Multi-Attribute Rating Technique}} ({{SMART}}) - Apppm},
  url = {http://wiki.doing-projects.org/index.php/Simple_Multi-Attribute_Rating_Technique_(SMART)},
  urldate = {2023-10-16},
  file = {/home/jon/Zotero/storage/IFYLQ68R/Simple_Multi-Attribute_Rating_Technique_(SMART).html}
}

@article{siregarResearchSimpleMultiAttribute2017,
  title = {Research of {{Simple Multi-Attribute Rating Technique}} for {{Decision Support}}},
  author = {Siregar, Dodi and Arisandi, Diki and Usman, Ari and Irwan, Dedy and Rahim, Robbi},
  date = {2017-12},
  journaltitle = {J. Phys.: Conf. Ser.},
  volume = {930},
  pages = {012015},
  issn = {1742-6588, 1742-6596},
  doi = {10.1088/1742-6596/930/1/012015},
  url = {https://iopscience.iop.org/article/10.1088/1742-6596/930/1/012015},
  urldate = {2023-10-16},
  abstract = {One of the roles of decision support system is that it can assist the decision maker in obtaining the appropriate alternative with the desired criteria, one of the methods that could apply for the decision maker is SMART method with multicriteria decision making. This multi-criteria decision-making theory has meaning where every alternative has criteria and has value and weight, and the author uses this approach to facilitate decision making with a compelling case. The problems discussed in this paper are classified into problems of a variety Multiobjective (multiple goals to be accomplished) and multicriteria (many of the decisive criteria in reaching such decisions).},
  langid = {english},
  file = {/home/jon/Zotero/storage/XUAV2GVK/Siregar et al. - 2017 - Research of Simple Multi-Attribute Rating Techniqu.pdf}
}

@article{sousaOrchestratorSelectionProcess2022,
  title = {Orchestrator Selection Process for Cloud-Native Machine Learning Experimentation},
  author = {Sousa, Afonso Rafael Carvalho},
  date = {2022},
  langid = {english},
  file = {/home/jon/Zotero/storage/KHHN6K8C/Sousa - 2022 - Orchestrator selection process for cloud-native ma.pdf}
}

@thesis{sousaOrchestratorSelectionProcess2022a,
  type = {mathesis},
  title = {Orchestrator Selection Process for Cloud-Native Machine Learning Experimentation},
  author = {Sousa, Afonso Rafael Carvalho},
  date = {2022},
  url = {https://repositorium.sdum.uminho.pt/handle/1822/83233},
  urldate = {2023-10-12},
  abstract = {Machine learning (ML) model development is a very experimental, repetitive, and error prone task,
 because ML is itself very obscure - there is no way to know what model works best for our goals beforehand,
 so practitioners have an incentive to experiment with as many models, approaches and techniques as they
 can. Additionally, going from raw data to a well adjusted model is a delicate process that often requires
 complex, multi-step pipelines. Combine the two factors and it becomes apparent how easy it is to get lost
 within a sea of artifacts and results without a well defined process, hindering the development process
 with poor reusability, lots of technical debt, and integration-hell. This makes adherence to best practices -
 MLOps - paramount.
 However, with the recent boom experienced in this field came a plethora of different tools and services,
 all trying to satisfy different subsets of needs of the model life cycle, meaning that, more often than not, ML
 practitioners do not know what the best set of tools for their use case might be. The experimental nature
 of ML means we should indeed try different tools, but there is a high risk that it might not fit the necessary
 requirements, generating needless costs. One particularly relevant type of tool is the orchestrator - a central
 piece of the experimentation process which controls the communication and execution of the components
 of a model pipeline.
 This work follows the creation process for an enterprise ML cloud environment, with particular focus
 on the selection of an adequate orchestrator for cloud-native setups. Additionally, it presents MetaTool, a
 web application designed to speed up future tool selection processes by leveraging knowledge gathered
 during previous instances.
 Finally, it reaches two key conclusions: first, broader organizational factors that might seem out of
 scope can influence or even alter the final choice, and second, although using a tool like MetaTool might
 speed up the decision-making process, it requires significant organizational commitment.},
  langid = {english},
  annotation = {Accepted: 2023-03-14T16:53:41Z},
  file = {/home/jon/Zotero/storage/54LNWFEP/Sousa - 2022 - Orchestrator selection process for cloud-native ma.pdf}
}

@software{SpotifyLuigi2023,
  title = {Spotify/Luigi},
  date = {2023-10-12T11:31:28Z},
  origdate = {2012-09-20T15:06:38Z},
  url = {https://github.com/spotify/luigi},
  urldate = {2023-10-12},
  abstract = {Luigi is a Python module that helps you build complex pipelines of batch jobs. It handles dependency resolution, workflow management, visualization etc. It also comes with Hadoop support built in.},
  organization = {{Spotify}},
  keywords = {hadoop,luigi,orchestration-framework,python,scheduling}
}

@incollection{triantaphyllouIntroductionMultiCriteriaDecision2000,
  title = {Introduction to {{Multi-Criteria Decision Making}}},
  booktitle = {Multi-Criteria {{Decision Making Methods}}: {{A Comparative Study}}},
  author = {Triantaphyllou, Evangelos},
  editor = {Triantaphyllou, Evangelos},
  date = {2000},
  series = {Applied {{Optimization}}},
  pages = {1--4},
  publisher = {{Springer US}},
  location = {{Boston, MA}},
  doi = {10.1007/978-1-4757-3157-6_1},
  url = {https://doi.org/10.1007/978-1-4757-3157-6_1},
  urldate = {2023-10-12},
  abstract = {The analysis of the way people make decisions (prescriptive theories) or the way people ought to make decisions (normative theories) is perhaps as old as the recorded history of mankind. Of course, not all these analyses were characterized by the rigorous scientific approaches we see in the literature today. Therefore, it is not surprising that the literature in decision making is humongous and continuously increasing. At the same time, however, the development of the perfect decision making method for rational real life decision making still remains an elusive goal. This contradiction between the extensiveness of the study on this subject and the elusiveness of the final goal of the real life applicability of the findings, constitutes in a way the ultimate decision making paradox.},
  isbn = {978-1-4757-3157-6},
  langid = {english}
}

@book{triantaphyllouMulticriteriaDecisionMaking2000,
  title = {Multi-Criteria {{Decision Making Methods}}: {{A Comparative Study}}},
  shorttitle = {Multi-Criteria {{Decision Making Methods}}},
  author = {Triantaphyllou, Evangelos},
  editorb = {Pardalos, Panos M. and Hearn, Donald},
  editorbtype = {redactor},
  date = {2000},
  series = {Applied {{Optimization}}},
  volume = {44},
  publisher = {{Springer US}},
  location = {{Boston, MA}},
  doi = {10.1007/978-1-4757-3157-6},
  url = {http://link.springer.com/10.1007/978-1-4757-3157-6},
  urldate = {2023-10-12},
  isbn = {978-1-4419-4838-0 978-1-4757-3157-6},
  keywords = {business,calculus,decision making,duality,fuzzy,fuzzy sets,multi-criteria decision making,multiple-criteria decision-making,sensitivity analysis},
  file = {/home/jon/Zotero/storage/CIF8KQQZ/Triantaphyllou - 2000 - Multi-criteria Decision Making Methods A Comparat.pdf}
}

@incollection{triantaphyllouMultiCriteriaDecisionMaking2000,
  title = {Multi-{{Criteria Decision Making Methods}}},
  booktitle = {Multi-Criteria {{Decision Making Methods}}: {{A Comparative Study}}},
  author = {Triantaphyllou, Evangelos},
  editor = {Triantaphyllou, Evangelos},
  date = {2000},
  series = {Applied {{Optimization}}},
  pages = {5--21},
  publisher = {{Springer US}},
  location = {{Boston, MA}},
  doi = {10.1007/978-1-4757-3157-6_2},
  url = {https://doi.org/10.1007/978-1-4757-3157-6_2},
  urldate = {2023-10-12},
  abstract = {With the continuing proliferation of decision methods and their variants, it is important to have an understanding of their comparative value. Each of the methods uses numeric techniques to help decision makers choose among a discrete set of alternative decisions. This is achieved on the basis of the impact of the alternatives on certain criteria and thereby on the overall utility of the decision maker(s). The difficulty that always occurs when trying to compare decision methods and choose the best one is that a paradox is reached, i.e., What decision-making method should be used to choose the best decision-making method? This problem is examined in Chapter 9.},
  isbn = {978-1-4757-3157-6},
  langid = {english},
  keywords = {Analytic Hierarchy Process,Concordance Index,Decision Matrix,ELECTRE Method,Ideal Solution}
}

@book{triantaphyllouMulticriteriaDecisionMaking2000a,
  title = {Multi-Criteria {{Decision Making Methods}}: {{A Comparative Study}}},
  shorttitle = {Multi-Criteria {{Decision Making Methods}}},
  author = {Triantaphyllou, Evangelos},
  editorb = {Pardalos, Panos M. and Hearn, Donald},
  editorbtype = {redactor},
  date = {2000},
  series = {Applied {{Optimization}}},
  volume = {44},
  publisher = {{Springer US}},
  location = {{Boston, MA}},
  doi = {10.1007/978-1-4757-3157-6},
  url = {http://link.springer.com/10.1007/978-1-4757-3157-6},
  urldate = {2023-10-12},
  isbn = {978-1-4419-4838-0 978-1-4757-3157-6},
  langid = {english},
  file = {/home/jon/Zotero/storage/A46N4GLR/Triantaphyllou - 2000 - Multi-criteria Decision Making Methods A Comparat}
}

@inreference{WeightedSumModel2022,
  title = {Weighted Sum Model},
  booktitle = {Wikipedia},
  date = {2022-10-05T12:24:18Z},
  url = {https://en.wikipedia.org/w/index.php?title=Weighted_sum_model&oldid=1114224941},
  urldate = {2023-10-16},
  abstract = {In decision theory, the weighted sum model (WSM), also called weighted linear combination (WLC) or simple additive weighting (SAW), is the best known and simplest multi-criteria decision analysis (MCDA) / multi-criteria decision making method for evaluating a number of alternatives in terms of a number of decision criteria.},
  langid = {english},
  annotation = {Page Version ID: 1114224941},
  file = {/home/jon/Zotero/storage/ETH97KSF/Weighted_sum_model.html}
}

@article{wildeMethodenspektrumWirtschaftsinformatikUeberblick,
  title = {Methodenspektrum der Wirtschaftsinformatik: Überblick und Portfoliobildung},
  author = {Wilde, Thomas and Hess, Thomas},
  langid = {ngerman},
  file = {/home/jon/Zotero/storage/89XM8EK6/Wilde and Hess - Methodenspektrum der Wirtschaftsinformatik Überbl.pdf}
}

@article{wrattenReproducibleScalableShareable2021,
  title = {Reproducible, Scalable, and Shareable Analysis Pipelines with Bioinformatics Workflow Managers},
  author = {Wratten, Laura and Wilm, Andreas and Göke, Jonathan},
  date = {2021-10},
  journaltitle = {Nat Methods},
  volume = {18},
  number = {10},
  pages = {1161--1168},
  publisher = {{Nature Publishing Group}},
  issn = {1548-7105},
  doi = {10.1038/s41592-021-01254-9},
  url = {https://www.nature.com/articles/s41592-021-01254-9},
  urldate = {2023-10-04},
  abstract = {The rapid growth of high-throughput technologies has transformed biomedical research. With the increasing amount and complexity of data, scalability and reproducibility have become essential not just for experiments, but also for computational analysis. However, transforming data into information involves running a large number of tools, optimizing parameters, and integrating dynamically changing reference data. Workflow managers were developed in response to such challenges. They simplify pipeline development, optimize resource usage, handle software installation and versions, and run on different compute platforms, enabling workflow portability and sharing. In this Perspective, we highlight key features of workflow managers, compare commonly used approaches for bioinformatics workflows, and provide a guide for computational and noncomputational users. We outline community-curated pipeline initiatives that enable novice and experienced users to perform complex, best-practice analyses without having to manually assemble workflows. In sum, we illustrate how workflow managers contribute to making computational analysis in biomedical research shareable, scalable, and reproducible.},
  issue = {10},
  langid = {english},
  keywords = {Computational platforms and environments,Programming language,Software}
}

@article{wrattenReproducibleScalableShareable2021a,
  title = {Reproducible, Scalable, and Shareable Analysis Pipelines with Bioinformatics Workflow Managers},
  author = {Wratten, Laura and Wilm, Andreas and Göke, Jonathan},
  date = {2021-10},
  journaltitle = {Nat Methods},
  volume = {18},
  number = {10},
  pages = {1161--1168},
  publisher = {{Nature Publishing Group}},
  issn = {1548-7105},
  doi = {10.1038/s41592-021-01254-9},
  url = {https://www.nature.com/articles/s41592-021-01254-9},
  urldate = {2023-10-07},
  abstract = {The rapid growth of high-throughput technologies has transformed biomedical research. With the increasing amount and complexity of data, scalability and reproducibility have become essential not just for experiments, but also for computational analysis. However, transforming data into information involves running a large number of tools, optimizing parameters, and integrating dynamically changing reference data. Workflow managers were developed in response to such challenges. They simplify pipeline development, optimize resource usage, handle software installation and versions, and run on different compute platforms, enabling workflow portability and sharing. In this Perspective, we highlight key features of workflow managers, compare commonly used approaches for bioinformatics workflows, and provide a guide for computational and noncomputational users. We outline community-curated pipeline initiatives that enable novice and experienced users to perform complex, best-practice analyses without having to manually assemble workflows. In sum, we illustrate how workflow managers contribute to making computational analysis in biomedical research shareable, scalable, and reproducible.},
  issue = {10},
  langid = {english},
  keywords = {Computational platforms and environments,Programming language,Software},
  file = {/home/jon/Zotero/storage/THDCD6IC/Wratten et al. - 2021 - Reproducible, scalable, and shareable analysis pip.pdf}
}

@inproceedings{yooSLURMSimpleLinux2003,
  title = {{{SLURM}}: {{Simple Linux Utility}} for {{Resource Management}}},
  shorttitle = {{{SLURM}}},
  booktitle = {Job {{Scheduling Strategies}} for {{Parallel Processing}}},
  author = {Yoo, Andy B. and Jette, Morris A. and Grondona, Mark},
  editor = {Feitelson, Dror and Rudolph, Larry and Schwiegelshohn, Uwe},
  date = {2003},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {44--60},
  publisher = {{Springer}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/10968987_3},
  abstract = {A new cluster resource management system called Simple Linux Utility Resource Management (SLURM) is described in this paper. SLURM, initially developed for large Linux clusters at the Lawrence Livermore National Laboratory (LLNL), is a simple cluster manager that can scale to thousands of processors. SLURM is designed to be flexible and fault-tolerant and can be ported to other clusters of different size and architecture with minimal effort. We are certain that SLURM will benefit both users and system architects by providing them with a simple, robust, and highly scalable parallel job execution environment for their cluster system.},
  isbn = {978-3-540-39727-4},
  langid = {english},
  keywords = {Exit Status,Lawrence Livermore National Laboratory,Message Authentication Code,Remote Execution,Resource Management System},
  file = {/home/jon/Zotero/storage/CIP9VDIE/Yoo et al. - 2003 - SLURM Simple Linux Utility for Resource Managemen.pdf}
}

@article{youScalingSupportVector2015,
  title = {Scaling {{Support Vector Machines}} on Modern {{HPC}} Platforms},
  author = {You, Yang and Fu, Haohuan and Song, Shuaiwen Leon and Randles, Amanda and Kerbyson, Darren and Marquez, Andres and Yang, Guangwen and Hoisie, Adolfy},
  date = {2015-02-01},
  journaltitle = {Journal of Parallel and Distributed Computing},
  series = {Special {{Issue}} on {{Architecture}} and {{Algorithms}} for {{Irregular Applications}}},
  volume = {76},
  pages = {16--31},
  issn = {0743-7315},
  doi = {10.1016/j.jpdc.2014.09.005},
  url = {https://www.sciencedirect.com/science/article/pii/S0743731514001683},
  urldate = {2023-10-03},
  abstract = {Support Vector Machines (SVM) have been widely used in data-mining and Big Data applications as modern commercial databases start to attach an increasing importance to the analytic capabilities. In recent years, SVM was adapted to the field of High Performance Computing for power/performance prediction, auto-tuning, and runtime scheduling. However, even at the risk of losing prediction accuracy due to insufficient runtime information, researchers can only afford to apply offline model training to avoid significant runtime training overhead. Advanced multi- and many-core architectures offer massive parallelism with complex memory hierarchies which can make runtime training possible, but form a barrier to efficient parallel SVM design. To address the challenges above, we designed and implemented MIC-SVM, a highly efficient parallel SVM for~x86 based multi-core and many-core architectures, such as the Intel Ivy Bridge CPUs and Intel Xeon Phi co-processor (MIC). We propose various novel analysis methods and optimization techniques to fully utilize the multilevel parallelism provided by these architectures and serve as general optimization methods for other machine learning tools. MIC-SVM achieves 4.4–84×~and 18–47×~speedups against the popular LIBSVM, on MIC and Ivy Bridge CPUs respectively, for several real-world data-mining datasets. Even compared with GPUSVM, running on the NVIDIA k20x~GPU, the performance of our MIC-SVM is competitive. We also conduct a cross-platform performance comparison analysis, focusing on Ivy Bridge CPUs, MIC and GPUs, and provide insights on how to select the most suitable advanced architectures for specific algorithms and input data patterns.},
  keywords = {Dynamic modeling,Machine learning models,Multi- \& many-core architectures,Optimization techniques,Performance analysis,Support Vector Machine},
  file = {/home/jon/Zotero/storage/VY6R76FR/You et al. - 2015 - Scaling Support Vector Machines on modern HPC plat.pdf;/home/jon/Zotero/storage/J3798C3J/S0743731514001683.html}
}

@article{zhouContainerOrchestrationHPC2021,
  title = {Container Orchestration on {{HPC}} Systems through {{Kubernetes}}},
  author = {Zhou, Naweiluo and Georgiou, Yiannis and Pospieszny, Marcin and Zhong, Li and Zhou, Huan and Niethammer, Christoph and Pejak, Branislav and Marko, Oskar and Hoppe, Dennis},
  date = {2021-02-22},
  journaltitle = {Journal of Cloud Computing},
  volume = {10},
  number = {1},
  pages = {16},
  issn = {2192-113X},
  doi = {10.1186/s13677-021-00231-z},
  url = {https://doi.org/10.1186/s13677-021-00231-z},
  urldate = {2023-07-02},
  abstract = {Containerisation demonstrates its efficiency in application deployment in Cloud Computing. Containers can encapsulate complex programs with their dependencies in isolated environments making applications more portable, hence are being adopted in High Performance Computing (HPC) clusters. Singularity, initially designed for HPC systems, has become their de facto standard container runtime. Nevertheless, conventional HPC workload managers lack micro-service support and deeply-integrated container management, as opposed to container orchestrators. We introduce a Torque-Operator which serves as a bridge between HPC workload manager (TORQUE) and container orchestrator (Kubernetes). We propose a hybrid architecture that integrates HPC and Cloud clusters seamlessly with little interference to HPC systems where container orchestration is performed on two levels.},
  keywords = {Cloud computing,Container orchestration,HPC workload manager,Kubernetes,Singularity,TORQUE},
  file = {/home/jon/Zotero/storage/UMHY2J4N/Zhou et al. - 2021 - Container orchestration on HPC systems through Kub.pdf;/home/jon/Zotero/storage/EYUHHD39/s13677-021-00231-z.html}
}

@online{zotero-41,
  pubstate = {preprint}
}
